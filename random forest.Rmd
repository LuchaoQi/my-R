


```{r}
rm(list = ls())
load(file = 'analyticData.rda')

PCnames = paste('PC',1:5,sep = '')
y = analyticData[,c('RIDAGEYR','Race','Gender','BMI',PCnames)] %>% na.omit()


set.seed(111)
id = sample(dim(y)[1],0.8*dim(y)[1])
if(F){
  fit = randomForest(BMI ~ ., data = y,ntree = 2000,
                     subset = id,
                     importance = T)
  save(fit,file = 'rffit.rda')
}
load(file = 'rffit.rda')
library(randomForest)
varImpPlot(fit,
           main = 'Variable Importance Measured by Random Forest')

ytest = y[-id,'BMI']
ypred = fit %>% predict(y[-id,])

cor(ytest,ypred)
mean((ytest-ypred)^2)
plot(ypred,ytest)
```












# predict over all features using lapply

```{r}
# glm

# idk why lapply doesnt work here so I use for loop
# regression_res = list()
# lapply(colnames(data), function(i){
#   fml = paste0(i,"~.") %>% as.formula()
#   model = glm(fml, family = gaussian, data = data)
#   regression_res[[i]] = as.list(summary(model))
# })

regression_res = list()

for (i in colnames(data)) {
  fml = paste0(i,"~.") %>% as.formula()
  model = glm(fml, family = gaussian, data = data)
  regression_res[[i]] = model
}

lapply(regression_res,summary)

# randomforest

library(randomForest)
lapply(colnames(data), function(i){
  # fml = paste0(i,"~.-",i) %>% as.formula()
  fml = paste0(i,"~.") %>% as.formula()
  data.rf = randomForest(fml, data, importance = TRUE)
  varImpPlot(data.rf,
             main = i)
})
```

